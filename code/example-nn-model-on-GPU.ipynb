{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0, 1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using -- cuda\n"
     ]
    }
   ],
   "source": [
    "# test GPU working (output should be \"Using -- cuda\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print( \"Using --\", device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code from : https://medium.com/analytics-vidhya/a-simple-neural-network-classifier-using-pytorch-from-scratch-7ebb477422d2\n",
    "\n",
    "# prepare data\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "X, Y = make_classification(\n",
    "  n_samples=100, n_features=4, n_redundant=0,\n",
    "  n_informative=3,  n_clusters_per_class=2, n_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "  X, Y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n"
     ]
    }
   ],
   "source": [
    "print( X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data loader for training data -- note the defining of two required methods (getitem and len)\n",
    "\n",
    "class Data(Dataset):\n",
    "  def __init__(self, X_train, y_train):\n",
    "    # need to convert float64 to float32 else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Double but found Float\n",
    "    self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "    # need to convert float64 to Long else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Long but found Float\n",
    "    self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "    self.len = self.X.shape[0]\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.y[index]\n",
    "  def __len__(self):\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the data loader for the actual data\n",
    "traindata = Data(X_train, Y_train)\n",
    "\n",
    "# accessing e.g. \n",
    "# print( traindata[23:25])\n",
    "\n",
    "# load into a DataLoader iterator so that accessing will return a batch at a time\n",
    "\n",
    "batch_size = 4\n",
    "trainloader = DataLoader(traindata, batch_size=batch_size, \n",
    "                         shuffle=True, num_workers=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# number of features (len of X cols)\n",
    "input_dim = 4\n",
    "\n",
    "# number of hidden nodes\n",
    "hidden_layers = 25\n",
    "\n",
    "# number of classes (unique of y)\n",
    "output_dim = 3\n",
    "class Network(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Network, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_dim, hidden_layers)\n",
    "    self.linear2 = nn.Linear(hidden_layers, output_dim)\n",
    "  \n",
    "  def forward_layer1( self, x ):\n",
    "    x = torch.sigmoid(self.linear1(x))\n",
    "    return x\n",
    "  \n",
    "  def forward_layer2( self, x ):\n",
    "    x = self.linear2(x)\n",
    "    return x \n",
    "  \n",
    "  def forward(self, x):\n",
    "    y = self.forward_layer1(x)\n",
    "    y = self.forward_layer2(y)\n",
    "    return y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Network(\n",
      "  (linear1): Linear(in_features=4, out_features=25, bias=True)\n",
      "  (linear2): Linear(in_features=25, out_features=3, bias=True)\n",
      ")>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (linear1): Linear(in_features=4, out_features=25, bias=True)\n",
       "  (linear2): Linear(in_features=25, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate network\n",
    "clf = Network()\n",
    "# define loss and optimizer algorithm\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(clf.parameters(), lr=0.1)\n",
    "\n",
    "print( clf.parameters )\n",
    "\n",
    "## load model to GPU\n",
    "clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-081167f7d7d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print(\" clf direct call : \", zz)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# test_input = torch.randn(1,1,1,4)\n",
    "# print( test_input )\n",
    "\n",
    "# #print( clf( test_input ) )\n",
    "\n",
    "# xx = clf.forward_layer1( test_input )\n",
    "# print( \" Output layer 1 = \", xx )\n",
    "\n",
    "# yy = clf.forward_layer2( xx )\n",
    "# print( \" Output layer 2 = \", yy )\n",
    "\n",
    "# zz = clf( test_input )\n",
    "# print(\" clf direct call : \", zz)\n",
    "\n",
    "for i, inputs, labels in trainloader:\n",
    "    print( inputs )\n",
    "    print( labels )\n",
    "    print( i )\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1,    18 ] loss: 0.00933\n",
      "[ 2,    18 ] loss: 0.00871\n",
      "[ 3,    18 ] loss: 0.00797\n",
      "[ 4,    18 ] loss: 0.00759\n",
      "[ 5,    18 ] loss: 0.00683\n",
      "[ 6,    18 ] loss: 0.00669\n",
      "[ 7,    18 ] loss: 0.00618\n",
      "[ 8,    18 ] loss: 0.00587\n"
     ]
    }
   ],
   "source": [
    "## GPU version of dataloader / training\n",
    "\n",
    "# training epochs\n",
    "epochs = 8\n",
    "for epoch in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  # iterate over trainloader (see above)\n",
    "  for inputs, labels in trainloader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # set optimizer to zero grad to remove previous epoch gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagation\n",
    "    outputs = clf(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    # optimize\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "\n",
    "  # display statistics\n",
    "  print(f'[ {epoch + 1} ] loss: {running_loss / 2000:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1,    17 ] loss: 0.00904\n",
      "[ 2,    17 ] loss: 0.00813\n",
      "[ 3,    17 ] loss: 0.00741\n",
      "[ 4,    17 ] loss: 0.00696\n",
      "[ 5,    17 ] loss: 0.00648\n",
      "[ 6,    17 ] loss: 0.00621\n",
      "[ 7,    17 ] loss: 0.00597\n",
      "[ 8,    17 ] loss: 0.00573\n"
     ]
    }
   ],
   "source": [
    "# training epochs\n",
    "epochs = 8\n",
    "for epoch in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  # enumerate over trainloader (see above)\n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    inputs, labels = data\n",
    "    # set optimizer to zero grad to remove previous epoch gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagation\n",
    "    outputs = clf(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    # optimize\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "\n",
    "  # display statistics\n",
    "  print(f'[ {epoch + 1}, {i + 1:5d} ] loss: {running_loss / 2000:.5f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network state for later re-use\n",
    "PATH = '../net-states/testing-only.pth'\n",
    "torch.save(clf.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load network state \n",
    "clf = None\n",
    "\n",
    "clf = Network()\n",
    "clf.load_state_dict( torch.load(PATH))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loader for test data\n",
    "testdata = Data(X_test, Y_test)\n",
    "testloader = DataLoader(testdata, batch_size=batch_size, \n",
    "                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4092, -0.1135,  0.2849],\n",
      "        [-0.5373, -0.8778,  1.1463],\n",
      "        [-0.4509, -1.2103,  1.4541]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# a single run of inference / forward prop only\n",
    "outputs = clf(inputs)\n",
    "print( outputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# apply max over 3 tuple (outputs) -- note, indexing starts at 0, so remember to add one\n",
    "\n",
    "__, predicted = torch.max(outputs, dim = 1)\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 33 test data: 54 %\n"
     ]
    }
   ],
   "source": [
    "# complete run through testing data set\n",
    "\n",
    "correct, total = 0, 0\n",
    "# no need to calculate gradients during inference\n",
    "with torch.no_grad():\n",
    "  for data in testloader:\n",
    "    inputs, labels = data\n",
    "    # calculate output by running through the network\n",
    "    outputs = clf(inputs)\n",
    "    # get the predictions\n",
    "    __, predicted = torch.max(outputs.data, 1)\n",
    "    # update results\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy of the network on the {len(testdata)} test data: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explain-paper",
   "language": "python",
   "name": "explain-paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
